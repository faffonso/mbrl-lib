# @package _group_
_target_: mbrl.models.GaussianMLP
device: ${device}
num_layers: 4
in_size: ???
out_size: ???
act_size: ???
affine: false
ensemble_size: 10
hid_size: 200
deterministic: false
propagation_method: random_model
learn_logvar_bounds: false  # so far this works better

activation_fn_cfg:
  _target_: torch.nn.SiLU